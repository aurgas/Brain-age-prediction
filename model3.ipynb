{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2fe5e7-dd49-4d12-a354-c6e4f6caeb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample path: E:\\Brain Age prediction\\Brain Age prediction\\disc1\\OAS1_0001_MR1\\processed\\MPRAGE\\T88_111\\OAS1_0001_MR1_mpr_n4_anon_111_t88_masked_gfc.hdr\n",
      "File exists: True\n",
      "Image shape: (176, 208, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# 1. Load and clean data\n",
    "df = pd.read_csv('merged_brain_age_hdr.csv', converters={'hdr_paths': ast.literal_eval})\n",
    "df['hdr_paths'] = df['hdr_paths'].apply(lambda x: [p.strip() for p in x if p.strip()])\n",
    "df['selected_hdr'] = df['hdr_paths'].apply(lambda x: x[1] if len(x)>=2 else None)\n",
    "df = df.dropna(subset=['selected_hdr']).reset_index(drop=True)\n",
    "\n",
    "# 2. Convert to absolute paths\n",
    "df['selected_hdr'] = df['selected_hdr'].apply(os.path.abspath)\n",
    "\n",
    "# 3. Validate paths\n",
    "df = df[df['selected_hdr'].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "# 4. Verify sample file\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty after filtering! Check file paths.\")\n",
    "else:\n",
    "    sample_path = df['selected_hdr'].iloc[0]\n",
    "    print(f\"Sample path: {sample_path}\")\n",
    "    print(f\"File exists: {os.path.exists(sample_path)}\")\n",
    "\n",
    "try:\n",
    "    sample_img = nib.load(sample_path)\n",
    "    print(f\"Image shape: {sample_img.header.get_data_shape()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading sample: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96917c91-93d1-42fb-829a-52fc5f6a1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddhant Jaiswal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "class BrainAgeDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, converters={'hdr_paths': ast.literal_eval})\n",
    "        self.data['hdr_paths'] = self.data['hdr_paths'].apply(lambda x: [p.strip() for p in x if p.strip()])\n",
    "        self.data['selected_hdr'] = self.data['hdr_paths'].apply(lambda x: x[1] if len(x) >= 2 else None)\n",
    "        self.data = self.data.dropna(subset=['selected_hdr']).reset_index(drop=True)\n",
    "        self.data['selected_hdr'] = self.data['selected_hdr'].apply(os.path.abspath)\n",
    "        self.data = self.data[self.data['selected_hdr'].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "        # Assign the transform correctly\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hdr_path = self.data.loc[idx, 'selected_hdr']\n",
    "        age = self.data.loc[idx, 'Age']\n",
    "    \n",
    "        img, age = self.load_3d_volume(hdr_path, age)\n",
    "    \n",
    "        if img is None:\n",
    "            raise ValueError(f\"Error loading image at index {idx}\")\n",
    "    \n",
    "        #print(f\"Initial image shape: {img.shape}\")  # (D, H, W, C)\n",
    "    \n",
    "        # Ensure the shape is (D, H, W, C)\n",
    "        if img.ndim == 3:  # If missing channel dimension\n",
    "            img = np.expand_dims(img, -1)\n",
    "    \n",
    "        #print(f\"Shape after adding channel: {img.shape}\")  # (D, H, W, C)\n",
    "    \n",
    "        # Apply augmentation if a transform is provided\n",
    "        if self.transform:\n",
    "            img_tensor = torch.tensor(img).permute(3, 0, 1, 2)  # (D, H, W, C) -> (C, D, H, W)\n",
    "            #print(f\"Shape before augmentation: {img_tensor.shape}\")  # (C, D, H, W)\n",
    "            img = self.transform(tio.ScalarImage(tensor=img_tensor)).tensor.numpy()\n",
    "            #print(f\"Shape after augmentation: {img.shape}\")  # (C, D, H, W)\n",
    "    \n",
    "        # Adjust the final shape to (C, D, H, W)\n",
    "        img = torch.tensor(img).permute(0, 1, 2, 3)  # Keep the original (C, D, H, W)\n",
    "    \n",
    "        #print(f\"Final shape before returning: {img.shape}\")  # (1, D, H, W)\n",
    "    \n",
    "        return img, torch.tensor(age, dtype=torch.float32)\n",
    "    \n",
    "        \n",
    "    def load_3d_volume(self, hdr_path, age):\n",
    "        try:\n",
    "            img = nib.load(hdr_path).get_fdata()\n",
    "\n",
    "            # Normalize to [0, 1]\n",
    "            min_val, max_val = img.min(), img.max()\n",
    "            img = (img - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "            if img.ndim == 3:  # (176, 208, 176) -> (176, 208, 176, 1)\n",
    "                img = np.expand_dims(img, -1)\n",
    "\n",
    "            return img.astype(np.float32), np.array(age, dtype=np.float32)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {hdr_path}: {e}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d8f6ce-2185-47d8-89a4-2ee1a304d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentations using TorchIO\n",
    "augmentations = tio.Compose([\n",
    "    tio.RandomAffine(scales=(1, 1), degrees=(0, 0, 15), translation=0),\n",
    "    tio.RandomBlur(p=0.3),\n",
    "    tio.RandomNoise(p=0.3)\n",
    "])\n",
    "\n",
    "# Datasets and DataLoader\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Load full dataset\n",
    "full_dataset = BrainAgeDataset(csv_file='merged_brain_age_hdr.csv', transform=augmentations)\n",
    "\n",
    "# Define split ratio (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=0)  # Fixed typo 'shuffel' -> 'shuffle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8633d86-31c4-43ef-88a9-fe4634e278ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Shallow3DCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=1):\n",
    "        super(Shallow3DCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, 16, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm3d(16)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2)  # (88, 104, 88)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm3d(32)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2)  # (44, 52, 44)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        \n",
    "        flattened_size = 32 * 44 * 52 * 44\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae8263e2-d86b-4ae9-a596-514593819013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate_model(model_class, X, y, k=5, epochs=10, batch_size=4, lr=1e-4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    all_fold_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "\n",
    "        model = model_class().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "        all_fold_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(\"\\nCross-validation complete.\")\n",
    "    print(f\"Avg Validation Loss across folds: {np.mean(all_fold_losses):.4f}\")\n",
    "    return all_fold_losses, all_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c3b59ca-fd4c-4897-96e9-b16ab1b5bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 50  \n",
    "X_dummy = np.random.rand(num_samples, 1, 176, 208, 176).astype(np.float32)\n",
    "y_dummy = np.random.rand(num_samples).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ad41a3-6dec-41ed-af79-463e8d937ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10 - Train Loss: 94165.0443 - Val Loss: 185.4079\n",
      "Epoch 2/10 - Train Loss: 1055.6514 - Val Loss: 75.2396\n",
      "Epoch 3/10 - Train Loss: 133.8908 - Val Loss: 5.4091\n",
      "Epoch 4/10 - Train Loss: 44.3650 - Val Loss: 29.6204\n",
      "Epoch 5/10 - Train Loss: 42.9800 - Val Loss: 4.6057\n",
      "Epoch 6/10 - Train Loss: 13.6528 - Val Loss: 9.8316\n",
      "Epoch 7/10 - Train Loss: 9.8022 - Val Loss: 2.0129\n",
      "Epoch 8/10 - Train Loss: 6.3097 - Val Loss: 0.4705\n",
      "Epoch 9/10 - Train Loss: 4.7990 - Val Loss: 5.2699\n",
      "Epoch 10/10 - Train Loss: 7.0774 - Val Loss: 1.4769\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10 - Train Loss: 90285.0504 - Val Loss: 1.0710\n",
      "Epoch 2/10 - Train Loss: 26.6662 - Val Loss: 0.6093\n",
      "Epoch 3/10 - Train Loss: 19.1680 - Val Loss: 3.7987\n",
      "Epoch 4/10 - Train Loss: 33.0224 - Val Loss: 0.8391\n",
      "Epoch 5/10 - Train Loss: 30.1966 - Val Loss: 20.0306\n",
      "Epoch 6/10 - Train Loss: 25.1098 - Val Loss: 44.3157\n",
      "Epoch 7/10 - Train Loss: 62.1123 - Val Loss: 38.7718\n",
      "Epoch 8/10 - Train Loss: 93.4420 - Val Loss: 37.4342\n",
      "Epoch 9/10 - Train Loss: 37.7891 - Val Loss: 0.7676\n",
      "Epoch 10/10 - Train Loss: 18.7938 - Val Loss: 20.4406\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10 - Train Loss: 86541.5673 - Val Loss: 28.5906\n",
      "Epoch 2/10 - Train Loss: 1184.2820 - Val Loss: 187.4555\n",
      "Epoch 3/10 - Train Loss: 471.5690 - Val Loss: 343.2128\n",
      "Epoch 4/10 - Train Loss: 557.7523 - Val Loss: 6.6322\n",
      "Epoch 5/10 - Train Loss: 277.1290 - Val Loss: 95.4251\n",
      "Epoch 6/10 - Train Loss: 167.2352 - Val Loss: 137.4461\n",
      "Epoch 7/10 - Train Loss: 135.5579 - Val Loss: 9.2175\n",
      "Epoch 8/10 - Train Loss: 85.4783 - Val Loss: 4.4048\n",
      "Epoch 9/10 - Train Loss: 23.6700 - Val Loss: 30.1667\n",
      "Epoch 10/10 - Train Loss: 37.0399 - Val Loss: 7.3784\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10 - Train Loss: 73910.9447 - Val Loss: 205.7106\n",
      "Epoch 2/10 - Train Loss: 828.4794 - Val Loss: 227.2963\n",
      "Epoch 3/10 - Train Loss: 403.4934 - Val Loss: 204.9453\n",
      "Epoch 4/10 - Train Loss: 211.0919 - Val Loss: 46.3831\n",
      "Epoch 5/10 - Train Loss: 152.9531 - Val Loss: 87.0994\n",
      "Epoch 6/10 - Train Loss: 63.1128 - Val Loss: 0.9249\n",
      "Epoch 7/10 - Train Loss: 24.6414 - Val Loss: 3.0404\n",
      "Epoch 8/10 - Train Loss: 17.2507 - Val Loss: 0.2669\n",
      "Epoch 9/10 - Train Loss: 3.5428 - Val Loss: 3.2816\n",
      "Epoch 10/10 - Train Loss: 1.6199 - Val Loss: 0.0864\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10 - Train Loss: 118056.2884 - Val Loss: 403.9050\n",
      "Epoch 2/10 - Train Loss: 3443.5733 - Val Loss: 16.1564\n",
      "Epoch 3/10 - Train Loss: 330.9185 - Val Loss: 8.6996\n",
      "Epoch 4/10 - Train Loss: 153.2405 - Val Loss: 100.6791\n",
      "Epoch 5/10 - Train Loss: 68.2335 - Val Loss: 0.1702\n",
      "Epoch 6/10 - Train Loss: 33.3172 - Val Loss: 3.9036\n",
      "Epoch 7/10 - Train Loss: 23.3019 - Val Loss: 0.1151\n",
      "Epoch 8/10 - Train Loss: 15.8710 - Val Loss: 2.5117\n",
      "Epoch 9/10 - Train Loss: 9.1603 - Val Loss: 2.2536\n",
      "Epoch 10/10 - Train Loss: 5.6208 - Val Loss: 0.8422\n",
      "\n",
      "Cross-validation complete.\n",
      "Avg Validation Loss across folds: 6.0449\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_val_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history, preds = \u001b[43mcross_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mShallow3DCNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (train_loss, val_loss) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(history):\n\u001b[32m      5\u001b[39m     plt.plot(train_loss, label=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTrain Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mcross_validate_model\u001b[39m\u001b[34m(model_class, X, y, k, epochs, batch_size, lr)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCross-validation complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvg Validation Loss across folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(all_fold_losses)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_fold_losses, \u001b[43mall_val_preds\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'all_val_preds' is not defined"
     ]
    }
   ],
   "source": [
    "history, preds = cross_validate_model(Shallow3DCNN, X_dummy, y_dummy, k=5, epochs=10, batch_size=4)\n",
    "\n",
    "\n",
    "for fold_idx, (train_loss, val_loss) in enumerate(history):\n",
    "    plt.plot(train_loss, label=f'Train Fold {fold_idx+1}')\n",
    "    plt.plot(val_loss, label=f'Val Fold {fold_idx+1}', linestyle='--')\n",
    "\n",
    "plt.title(\"Training & Validation Loss per Fold\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bc841-9935-4b5c-9e5a-45fd2596b861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
