{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c37fdf-620f-4e9a-9ef8-dda7f69dbda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample path: E:\\Brain Age prediction\\Brain Age prediction\\disc1\\OAS1_0001_MR1\\processed\\MPRAGE\\T88_111\\OAS1_0001_MR1_mpr_n4_anon_111_t88_masked_gfc.hdr\n",
      "File exists: True\n",
      "Image shape: (176, 208, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# 1. Load and clean data\n",
    "df = pd.read_csv('merged_brain_age_hdr.csv', converters={'hdr_paths': ast.literal_eval})\n",
    "df['hdr_paths'] = df['hdr_paths'].apply(lambda x: [p.strip() for p in x if p.strip()])\n",
    "df['selected_hdr'] = df['hdr_paths'].apply(lambda x: x[1] if len(x)>=2 else None)\n",
    "df = df.dropna(subset=['selected_hdr']).reset_index(drop=True)\n",
    "\n",
    "# 2. Convert to absolute paths\n",
    "df['selected_hdr'] = df['selected_hdr'].apply(os.path.abspath)\n",
    "\n",
    "# 3. Validate paths\n",
    "df = df[df['selected_hdr'].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "# 4. Verify sample file\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty after filtering! Check file paths.\")\n",
    "else:\n",
    "    sample_path = df['selected_hdr'].iloc[0]\n",
    "    print(f\"Sample path: {sample_path}\")\n",
    "    print(f\"File exists: {os.path.exists(sample_path)}\")\n",
    "\n",
    "try:\n",
    "    sample_img = nib.load(sample_path)\n",
    "    print(f\"Image shape: {sample_img.header.get_data_shape()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading sample: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcbcbfc-763c-4132-ac42-5208f995eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (176, 208, 176, 1) | Age: 74.0\n"
     ]
    }
   ],
   "source": [
    "def load_3d_volume(hdr_path, age):\n",
    "    try:\n",
    "        # Ensure hdr_path is a string\n",
    "        if not isinstance(hdr_path, str):\n",
    "            hdr_path = hdr_path.decode('utf-8')\n",
    "        \n",
    "        # Load NIfTI file\n",
    "        img = nib.load(hdr_path).get_fdata()\n",
    "\n",
    "        # Normalize to [0, 1] with epsilon to avoid division by zero\n",
    "        min_val, max_val = img.min(), img.max()\n",
    "        img = (img - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "        # Add channel dimension if missing\n",
    "        if img.ndim == 3:\n",
    "            img = np.expand_dims(img, -1)  # Shape: (D, H, W, 1)\n",
    "\n",
    "        return img.astype(np.float32), np.array(age, dtype=np.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {hdr_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "sample_path = df['selected_hdr'].iloc[0]\n",
    "sample_age = df['Age'].iloc[0]\n",
    "\n",
    "img, age = load_3d_volume(sample_path, sample_age)\n",
    "print(f\"Image shape: {img.shape} | Age: {age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b47bb6-a955-4df1-8824-ae9290288099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "class BrainAgeDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, converters={'hdr_paths': ast.literal_eval})\n",
    "        self.data['hdr_paths'] = self.data['hdr_paths'].apply(lambda x: [p.strip() for p in x if p.strip()])\n",
    "        self.data['selected_hdr'] = self.data['hdr_paths'].apply(lambda x: x[1] if len(x) >= 2 else None)\n",
    "        self.data = self.data.dropna(subset=['selected_hdr']).reset_index(drop=True)\n",
    "        self.data['selected_hdr'] = self.data['selected_hdr'].apply(os.path.abspath)\n",
    "        self.data = self.data[self.data['selected_hdr'].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "        # Assign the transform correctly\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hdr_path = self.data.loc[idx, 'selected_hdr']\n",
    "        age = self.data.loc[idx, 'Age']\n",
    "    \n",
    "        img, age = self.load_3d_volume(hdr_path, age)\n",
    "    \n",
    "        if img is None:\n",
    "            raise ValueError(f\"Error loading image at index {idx}\")\n",
    "    \n",
    "        #print(f\"Initial image shape: {img.shape}\")  # (D, H, W, C)\n",
    "    \n",
    "        # Ensure the shape is (D, H, W, C)\n",
    "        if img.ndim == 3:  # If missing channel dimension\n",
    "            img = np.expand_dims(img, -1)\n",
    "    \n",
    "        #print(f\"Shape after adding channel: {img.shape}\")  # (D, H, W, C)\n",
    "    \n",
    "        # Apply augmentation if a transform is provided\n",
    "        if self.transform:\n",
    "            img_tensor = torch.tensor(img).permute(3, 0, 1, 2)  # (D, H, W, C) -> (C, D, H, W)\n",
    "            #print(f\"Shape before augmentation: {img_tensor.shape}\")  # (C, D, H, W)\n",
    "            img = self.transform(tio.ScalarImage(tensor=img_tensor)).tensor.numpy()\n",
    "            #print(f\"Shape after augmentation: {img.shape}\")  # (C, D, H, W)\n",
    "    \n",
    "        # Adjust the final shape to (C, D, H, W)\n",
    "        img = torch.tensor(img).permute(0, 1, 2, 3)  # Keep the original (C, D, H, W)\n",
    "    \n",
    "        #print(f\"Final shape before returning: {img.shape}\")  # (1, D, H, W)\n",
    "    \n",
    "        return img, torch.tensor(age, dtype=torch.float32)\n",
    "    \n",
    "        \n",
    "    def load_3d_volume(self, hdr_path, age):\n",
    "        try:\n",
    "            img = nib.load(hdr_path).get_fdata()\n",
    "\n",
    "            # Normalize to [0, 1]\n",
    "            min_val, max_val = img.min(), img.max()\n",
    "            img = (img - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "            if img.ndim == 3:  # (176, 208, 176) -> (176, 208, 176, 1)\n",
    "                img = np.expand_dims(img, -1)\n",
    "\n",
    "            return img.astype(np.float32), np.array(age, dtype=np.float32)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {hdr_path}: {e}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceee1c37-e5c3-46eb-bc48-4556dd673330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class My3DBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_prob = .3):\n",
    "        super(My3DBlock,self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv3d(out_channels, out_channels, kernel_size = 3, padding = 1)\n",
    "        self.conv4 = nn.Conv3d(out_channels, out_channels, kernel_size = 3, padding = 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size = 2, stride = 2)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7475c69-cb2a-4bac-b85b-41c396057ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainAgeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainAgeModel, self).__init__()\n",
    "        \n",
    "        # Define the 4 My3DBlocks\n",
    "        self.block1 = My3DBlock(1, 16)    # Input has 1 channel\n",
    "        self.block2 = My3DBlock(16, 32)\n",
    "        self.block3 = My3DBlock(32, 64)\n",
    "        self.block4 = My3DBlock(64, 128)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 11 * 13 * 11, 128)  # Adjust dimensions based on input size\n",
    "        self.fc2 = nn.Linear(128, 1)  # Output: Regression (age prediction)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.4)  # Additional dropout before the final layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Shape: (batch_size, flattened_features)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f76381-614a-4f0f-bbbb-4e08a2918948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define augmentations using TorchIO\n",
    "augmentations = tio.Compose([\n",
    "    tio.RandomAffine(scales=(1, 1), degrees=(0, 0, 15), translation=0),\n",
    "    tio.RandomBlur(p=0.3),\n",
    "    tio.RandomNoise(p=0.3)\n",
    "])\n",
    "\n",
    "# Datasets and DataLoader\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Load full dataset\n",
    "full_dataset = BrainAgeDataset(csv_file='merged_brain_age_hdr.csv', transform=augmentations)\n",
    "\n",
    "# Define split ratio (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=0)  # Fixed typo 'shuffel' -> 'shuffle'\n",
    "\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BrainAgeModel().to(device)\n",
    "criterion = nn.MSELoss()  # For regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78bf8aeb-d059-473a-9382-0867738de3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 176, 208, 176])\n",
      "Output shape: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Model instance\n",
    "model = BrainAgeModel()\n",
    "\n",
    "# Test with dummy input (batch_size=2)\n",
    "sample_input = torch.rand(1, 1, 176, 208, 176)  # Adjust shape as needed\n",
    "output = model(sample_input)\n",
    "\n",
    "print(f\"Input shape: {sample_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")  # Expected: (batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c62fbed-d86c-4b80-9327-9076d028e701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddhant Jaiswal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchio\\data\\image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 1375.4220, Val Loss: 1077.2207\n",
      "Epoch [2/10] - Train Loss: 804.0489, Val Loss: 606.1556\n",
      "Epoch [3/10] - Train Loss: 730.5050, Val Loss: 613.8200\n",
      "Epoch [4/10] - Train Loss: 750.2138, Val Loss: 605.4150\n",
      "Epoch [5/10] - Train Loss: 747.0973, Val Loss: 610.4305\n",
      "Epoch [6/10] - Train Loss: 684.8285, Val Loss: 886.2824\n",
      "Epoch [7/10] - Train Loss: 763.7273, Val Loss: 604.8235\n",
      "Epoch [8/10] - Train Loss: 781.2485, Val Loss: 611.8008\n",
      "Epoch [9/10] - Train Loss: 730.3856, Val Loss: 843.1059\n",
      "Epoch [10/10] - Train Loss: 736.4224, Val Loss: 654.9553\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Trains the model and evaluates on validation set.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        optimizer (Optimizer): Optimization algorithm.\n",
    "        device (torch.device): Device to run the training (CPU/GPU).\n",
    "        num_epochs (int): Number of epochs.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # ---------------- TRAINING PHASE ----------------\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs.squeeze(), targets)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # ---------------- VALIDATION PHASE ----------------\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():  # No gradient calculation during validation\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Print loss per epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------ CALL TRAINING FUNCTION ------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Assuming regression task (age prediction)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Call the training function using your existing model and dataloaders\n",
    "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83d8463-61d0-48c4-b95b-3b09a9230c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 - Loss: 3795.8010 \n",
      "Batch 2 - Loss: 3280.9177 \n",
      "Batch 3 - Loss: 17971.0859 \n"
     ]
    }
   ],
   "source": [
    "def quick_test():\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Batch {i+1} - Loss: {loss.item():.4f} \")\n",
    "        if i == 2:\n",
    "            break\n",
    "\n",
    "\n",
    "quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0d211-eea9-4544-ba2a-0c69fe68c34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
